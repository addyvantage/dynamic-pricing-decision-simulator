"""Executive strategy scorecards for scenario evaluation.

Why scorecards (not dashboards):
- Leadership needs a fast, consistent summary for strategy trade-off decisions.
- Strategy-level averages and totals are sufficient for first-pass comparison before deep dives.
- Efficiency metrics (revenue per stress unit) prevent over-indexing on revenue while ignoring operational cost.
"""

from pathlib import Path

import numpy as np
import pandas as pd

INPUT_PATH = Path("simulation_engine/output/scenario_outcomes.csv")
OUTPUT_PATH = Path("evaluation_metrics/output/strategy_scorecard.csv")


def load_outcomes() -> pd.DataFrame:
    """Load scenario outcomes generated by the simulation layer as the single source of truth."""
    df = pd.read_csv(INPUT_PATH)
    return df


def compute_strategy_metrics(df: pd.DataFrame) -> pd.DataFrame:
    """Aggregate row-level scenario outcomes into strategy-level decision metrics."""
    grouped = (
        df.groupby("strategy_name", as_index=False)
        .agg(
            total_revenue=("revenue_est", "sum"),
            total_forecast_demand=("forecast_demand", "sum"),
            total_orders_completed=("orders_completed", "sum"),
            avg_utilization_rate=("utilization_rate", "mean"),
            avg_stress_index=("stress_index", "mean"),
            pct_high_risk_rows=("customer_risk_flag", lambda s: (s == "HIGH").mean() * 100.0),
            pct_medium_or_high_risk_rows=(
                "customer_risk_flag",
                lambda s: s.isin(["MEDIUM", "HIGH"]).mean() * 100.0,
            ),
        )
    )

    grouped["pct_demand_lost_capacity"] = np.where(
        grouped["total_forecast_demand"] > 0,
        (grouped["total_forecast_demand"] - grouped["total_orders_completed"]) / grouped["total_forecast_demand"] * 100.0,
        0.0,
    )

    grouped["revenue_per_stress_unit"] = np.where(
        grouped["avg_stress_index"] > 0,
        grouped["total_revenue"] / grouped["avg_stress_index"],
        0.0,
    )

    baseline_revenue = grouped.loc[grouped["strategy_name"] == "STATIC_BASELINE", "total_revenue"]
    baseline_value = float(baseline_revenue.iloc[0]) if not baseline_revenue.empty else np.nan

    grouped["revenue_lift_vs_baseline_pct"] = np.where(
        baseline_value > 0,
        (grouped["total_revenue"] - baseline_value) / baseline_value * 100.0,
        np.nan,
    )

    col_order = [
        "strategy_name",
        "total_revenue",
        "revenue_lift_vs_baseline_pct",
        "total_forecast_demand",
        "total_orders_completed",
        "pct_demand_lost_capacity",
        "avg_utilization_rate",
        "avg_stress_index",
        "pct_high_risk_rows",
        "pct_medium_or_high_risk_rows",
        "revenue_per_stress_unit",
    ]

    grouped = grouped[col_order]

    strategy_order = ["STATIC_BASELINE", "POLICY_RECOMMENDED", "AGGRESSIVE_POLICY"]
    grouped["strategy_name"] = pd.Categorical(grouped["strategy_name"], categories=strategy_order, ordered=True)
    grouped = grouped.sort_values("strategy_name").reset_index(drop=True)

    return grouped


def format_scorecard(metrics_df: pd.DataFrame) -> pd.DataFrame:
    """Round and label metrics for executive-readable console and CSV output."""
    out = metrics_df.copy()

    round_map = {
        "total_revenue": 2,
        "revenue_lift_vs_baseline_pct": 2,
        "total_forecast_demand": 2,
        "total_orders_completed": 2,
        "pct_demand_lost_capacity": 2,
        "avg_utilization_rate": 3,
        "avg_stress_index": 2,
        "pct_high_risk_rows": 2,
        "pct_medium_or_high_risk_rows": 2,
        "revenue_per_stress_unit": 2,
    }

    for col, ndigits in round_map.items():
        out[col] = out[col].round(ndigits)

    return out


def print_scorecard(formatted_df: pd.DataFrame) -> None:
    """Print an aligned strategy comparison table and three auto-generated executive insights."""
    display_cols = [
        "strategy_name",
        "total_revenue",
        "revenue_lift_vs_baseline_pct",
        "pct_demand_lost_capacity",
        "avg_stress_index",
        "pct_high_risk_rows",
        "revenue_per_stress_unit",
    ]

    headers = {
        "strategy_name": "strategy",
        "total_revenue": "total_revenue",
        "revenue_lift_vs_baseline_pct": "revenue_lift_vs_baseline_pct",
        "pct_demand_lost_capacity": "pct_demand_lost_capacity",
        "avg_stress_index": "avg_stress_index",
        "pct_high_risk_rows": "pct_high_risk_rows",
        "revenue_per_stress_unit": "revenue_per_stress_unit",
    }

    table = formatted_df[display_cols].rename(columns=headers)

    print("Strategy Scorecard")
    print(table.to_string(index=False))

    by_name = {r["strategy_name"]: r for _, r in formatted_df.iterrows()}
    baseline = by_name["STATIC_BASELINE"]
    recommended = by_name["POLICY_RECOMMENDED"]
    aggressive = by_name["AGGRESSIVE_POLICY"]

    rec_rev_lift = recommended["revenue_lift_vs_baseline_pct"]
    rec_vs_agg_stress_delta = aggressive["avg_stress_index"] - recommended["avg_stress_index"]
    agg_vs_rec_eff_delta = recommended["revenue_per_stress_unit"] - aggressive["revenue_per_stress_unit"]
    base_rev_gap = recommended["total_revenue"] - baseline["total_revenue"]

    print("\nInsights")
    print(
        f"- POLICY_RECOMMENDED delivers +{rec_rev_lift:.2f}% revenue lift vs STATIC_BASELINE while keeping average stress {rec_vs_agg_stress_delta:.2f} points lower than AGGRESSIVE_POLICY."
    )
    print(
        f"- AGGRESSIVE_POLICY underperforms on efficiency, with revenue_per_stress_unit {agg_vs_rec_eff_delta:.2f} lower than POLICY_RECOMMENDED despite higher price intensity."
    )
    print(
        f"- STATIC_BASELINE is the lowest-risk reference, but leaves {base_rev_gap:,.2f} in revenue unrealized versus POLICY_RECOMMENDED."
    )


def save_scorecard(formatted_df: pd.DataFrame) -> None:
    """Persist the strategy scorecard for downstream review and interview-ready sharing."""
    OUTPUT_PATH.parent.mkdir(parents=True, exist_ok=True)
    formatted_df.to_csv(OUTPUT_PATH, index=False)
    print(f"\nSaved scorecard: {OUTPUT_PATH}")


def run_scorecards() -> pd.DataFrame:
    """Run the full evaluation flow from outcomes loading to printed and saved scorecards."""
    outcomes = load_outcomes()
    metrics = compute_strategy_metrics(outcomes)
    formatted = format_scorecard(metrics)
    print_scorecard(formatted)
    save_scorecard(formatted)
    return formatted


if __name__ == "__main__":
    run_scorecards()
